{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9365e1a1-9885-427e-b160-02f7f879b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('PAMAP2_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff147320-a9ef-484c-a8fc-b4c11158075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Activities: 10\n",
      "labels: ['lying' 'sitting' 'standing' 'standing_household_chores'\n",
      " 'ascending_stairs' 'descending_stairs' 'walking' 'Nordic_walking'\n",
      " 'cycling' 'jumping']\n"
     ]
    }
   ],
   "source": [
    "# Get unique activities from the \"Activity\" column (assuming there is an Activity column)\n",
    "unique_activities = df['label'].unique()\n",
    "\n",
    "# Print the number of unique activities\n",
    "print('Number of Unique Activities: {}'.format(len(unique_activities)))\n",
    "\n",
    "# Optionally, print the unique activity names\n",
    "print('labels:', unique_activities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80539a3e-4415-4d07-8fd2-87b41d2da07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time_stamp', 'label', 'hand_3D_acceleration_16_x',\n",
      "       'hand_3D_acceleration_16_y', 'hand_3D_acceleration_16_z',\n",
      "       'hand_3D_acceleration_6_x', 'hand_3D_acceleration_6_y',\n",
      "       'hand_3D_acceleration_6_z', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4512116c-32d4-4ab6-b801-35ddb250b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be dropped\n",
    "columns_to_drop = [\n",
    "'hand_3D_acceleration_16_x',\n",
    "       'hand_3D_acceleration_16_y', 'hand_3D_acceleration_16_z'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' will ignore any errors if a column is not found\n",
    "df = df.rename(columns={'id': 'user_id'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd4d9b3c-d865-488f-9793-b1f357f6f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time_stamp', 'label', 'hand_3D_acceleration_6_x',\n",
      "       'hand_3D_acceleration_6_y', 'hand_3D_acceleration_6_z', 'user_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d4edab0-d80d-4526-8c4e-b67476560b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp in row 1: 37.66\n",
      "Timestamp in row 10: 38.56\n",
      "Time difference in milliseconds: 0.9000000000000057 ms\n",
      "Time difference in seconds: 0.0009000000000000057 seconds\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame with a 'time' column\n",
    "\n",
    "# Print timestamps of row 1 and row 10\n",
    "timestamp_row_1 = df['time_stamp'].iloc[0]\n",
    "timestamp_row_10 = df['time_stamp'].iloc[90]\n",
    "\n",
    "print(f\"Timestamp in row 1: {timestamp_row_1}\")\n",
    "print(f\"Timestamp in row 10: {timestamp_row_10}\")\n",
    "\n",
    "# Calculate the time difference in milliseconds\n",
    "time_difference_ms = timestamp_row_10 - timestamp_row_1\n",
    "print(f\"Time difference in milliseconds: {time_difference_ms} ms\")\n",
    "\n",
    "# Convert to seconds if needed\n",
    "time_difference_seconds = time_difference_ms / 1000\n",
    "print(f\"Time difference in seconds: {time_difference_seconds} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "450b8c87-c47e-4dce-acac-99d0cbf2de60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'windowed_features.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "window_size = 170  # Number of rows per window\n",
    "step_size = 30     # Step size for 80% overlap (150 * 0.2 = 30)\n",
    "\n",
    "# List to store the windows\n",
    "windows = []\n",
    "\n",
    "# Unique window ID counter\n",
    "window_id = 0\n",
    "\n",
    "# Group by user ID and activity label to avoid mixing data from different users or activities\n",
    "for label, group_data in df.groupby(['label']):\n",
    "    # Create windows of 150 rows with 80% overlap within each group\n",
    "    for start in range(0, len(group_data) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = group_data.iloc[start:end].copy()  # Create a copy of the window\n",
    "        window['window_id'] = window_id  # Assign a unique window_id to each window\n",
    "        windows.append(window)\n",
    "        window_id += 1  # Increment the window_id for the next window\n",
    "\n",
    "# Combine all windows into a single DataFrame\n",
    "windowed_data = pd.concat(windows, ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame with window IDs to a new CSV file\n",
    "windowed_data.to_csv('PAMAP_window.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'windowed_features.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2714-c8f3-477e-aedc-e73b47f07c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbca2786-d4ae-4c5d-8e3a-b01e3288f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61438"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the generated windowed data\n",
    "windowed_data = pd.read_csv('PAMAP_window.csv')\n",
    "\n",
    "# Count the unique window IDs to determine the number of windows\n",
    "num_windows = windowed_data['window_id'].nunique()\n",
    "\n",
    "num_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c07253f-0bd5-44a3-b73d-d48b82a087ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_stamp           label  hand_3D_acceleration_6_x  \\\n",
      "0     2540.13  Nordic_walking                   1.75241   \n",
      "1     2540.14  Nordic_walking                   1.75152   \n",
      "2     2540.15  Nordic_walking                   1.88310   \n",
      "3     2540.16  Nordic_walking                   1.95351   \n",
      "4     2540.17  Nordic_walking                   1.93628   \n",
      "\n",
      "   hand_3D_acceleration_6_y  hand_3D_acceleration_6_z  user_id  window_id  \n",
      "0                   8.31466                   4.54929      101          0  \n",
      "1                   8.20895                   4.54953      101          0  \n",
      "2                   7.83034                   4.44452      101          0  \n",
      "3                   7.34646                   4.33980      101          0  \n",
      "4                   7.13511                   4.29498      101          0  \n"
     ]
    }
   ],
   "source": [
    "print(windowed_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e50418e7-5ef4-4732-a9e6-88c47716014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, iqr, entropy\n",
    "from numpy.fft import fft\n",
    "\n",
    "def calculate_features(window):\n",
    "    features = {}\n",
    "    axes = {'hand_3D_acceleration_6_x': 'Ax', 'hand_3D_acceleration_6_y': 'Ay', 'hand_3D_acceleration_6_z': 'Az'}\n",
    " \n",
    "    for axis in axes.keys():\n",
    "        data = window[axis]\n",
    "\n",
    "        # Handle NaN and infinite values\n",
    "        data = data.replace([np.inf, -np.inf], np.nan)  # Replace infinities if any\n",
    "        data = data.dropna()  # Drop NaN values\n",
    "        \n",
    "        if data.empty:\n",
    "            continue  \n",
    "\n",
    "        features[f'{axes[axis]}_mean'] = np.mean(data)\n",
    "        features[f'{axes[axis]}_std'] = np.std(data)\n",
    "        features[f'{axes[axis]}_mad'] = np.mean(np.abs(data - np.mean(data)))\n",
    "        features[f'{axes[axis]}_max'] = np.max(data)\n",
    "        features[f'{axes[axis]}_min'] = np.min(data)\n",
    "        features[f'{axes[axis]}_sma'] = np.sum(np.abs(data)) / len(data)\n",
    "        features[f'{axes[axis]}_energy'] = np.sum(data ** 2) / len(data)\n",
    "        features[f'{axes[axis]}_iqr'] = iqr(data)\n",
    "\n",
    "        # Adjust histogram calculation for better handling\n",
    "        if len(data) > 0:\n",
    "            hist, _ = np.histogram(data.dropna(), bins=10)  # Ensure no NaN values are included\n",
    "            features[f'{axes[axis]}_entropy'] = entropy(hist + 1e-6) if np.sum(hist) > 0 else 0\n",
    "\n",
    "        # Frequency-domain features\n",
    "        freq_data = np.abs(fft(data))[:len(data) // 2]\n",
    "        features[f'{axes[axis]}_meanFreq'] = np.sum(freq_data * np.arange(len(freq_data))) / np.sum(freq_data)\n",
    "        features[f'{axes[axis]}_skewness'] = skew(data)\n",
    "        features[f'{axes[axis]}_kurtosis'] = kurtosis(data)\n",
    "        features[f'{axes[axis]}_maxInds'] = np.argmax(freq_data)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10dd14b7-bae6-4ffa-92f5-9914dfb632d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ax_mean': 2.4330838, 'Ax_std': 0.26002258752185353, 'Ax_mad': 0.20469862799999997, 'Ax_max': 3.19561, 'Ax_min': 1.73618, 'Ax_sma': 2.4330838, 'Ax_energy': 5.9875085238439985, 'Ax_iqr': 0.34789749999999975, 'Ax_entropy': 1.953732479947525, 'Ax_meanFreq': 3.415159872686383, 'Ax_skewness': 0.3902649421222907, 'Ax_kurtosis': 0.6722250930175475, 'Ax_maxInds': 0, 'Ay_mean': 7.249486899999999, 'Ay_std': 0.8100411180707988, 'Ay_mad': 0.59513181, 'Ay_max': 9.356, 'Ay_min': 4.797, 'Ay_sma': 7.249486899999999, 'Ay_energy': 53.211226926236996, 'Ay_iqr': 0.8751875, 'Ay_entropy': 1.9215460865365317, 'Ay_meanFreq': 4.260739702768555, 'Ay_skewness': -0.5407542811447026, 'Ay_kurtosis': 1.0637693775134318, 'Ay_maxInds': 0, 'Az_mean': 6.2490127, 'Az_std': 0.7793498932993512, 'Az_mad': 0.58268937, 'Az_max': 8.77914, 'Az_min': 4.54805, 'Az_sma': 6.2490127, 'Az_energy': 39.65754598094699, 'Az_iqr': 0.8350075000000006, 'Az_entropy': 1.9502250763805522, 'Az_meanFreq': 2.68427453768784, 'Az_skewness': 0.5690683910581422, 'Az_kurtosis': 1.1507792509271297, 'Az_maxInds': 0}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is properly loaded and contains the correct columns\n",
    "window = df.iloc[:100]  # Taking the first 100 rows as a sample window\n",
    "features = calculate_features(window)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7cc0317b-61a6-4530-914a-4036905e8a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features: ['X_mean', 'X_std', 'X_mad', 'X_max', 'X_min', 'X_sma', 'X_energy', 'X_iqr', 'X_entropy', 'X_meanFreq', 'X_skewness', 'X_kurtosis', 'X_maxInds', 'Y_mean', 'Y_std', 'Y_mad', 'Y_max', 'Y_min', 'Y_sma', 'Y_energy', 'Y_iqr', 'Y_entropy', 'Y_meanFreq', 'Y_skewness', 'Y_kurtosis', 'Y_maxInds', 'Z_mean', 'Z_std', 'Z_mad', 'Z_max', 'Z_min', 'Z_sma', 'Z_energy', 'Z_iqr', 'Z_entropy', 'Z_meanFreq', 'Z_skewness', 'Z_kurtosis', 'Z_maxInds']\n"
     ]
    }
   ],
   "source": [
    "# Define the axes\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "# Generate the full list of features\n",
    "feature_list = []\n",
    "for axis in axes:\n",
    "    feature_list.extend([\n",
    "        f'{axis}_mean', f'{axis}_std', f'{axis}_mad', f'{axis}_max', f'{axis}_min',\n",
    "        f'{axis}_sma', f'{axis}_energy', f'{axis}_iqr', f'{axis}_entropy',\n",
    "        f'{axis}_meanFreq', f'{axis}_skewness', f'{axis}_kurtosis', f'{axis}_maxInds'\n",
    "    ])\n",
    "\n",
    "# Print the generated list of features\n",
    "print(\"Extracted Features:\", feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "caec9fc0-eebd-4df0-aa56-f59efe8b8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'train_data_features.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# List to store each window's features\n",
    "features_list = []\n",
    "df = df.rename(columns={'id': 'user_id'})\n",
    "\n",
    "# Process each window to calculate features\n",
    "for window in windows:\n",
    "    if not window.empty:\n",
    "        window_id = window['window_id'].iloc[0]  # Ensure 'window_id' is a column in df\n",
    "        label = window['label'].iloc[0]  # Ensure 'label' is a column in df\n",
    "        user_id = window['user_id'].iloc[0]  # Ensure 'user_id' is a column in df\n",
    "\n",
    "        # Calculate features and add identifiers\n",
    "        features = calculate_features(window)\n",
    "        features['window_id'] = window_id\n",
    "        features['label'] = label\n",
    "        features['user_id'] = user_id\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "# Convert the list of feature dictionaries to a DataFrame\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Save the features to a new CSV file\n",
    "features_df.to_csv('window_id.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'train_data_features.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec2c581a-d273-4ec9-b877-72f4437e9fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (48059, 42)\n",
      "Test data shape: (16651, 42)\n",
      "Train and test datasets saved as 'train_split.csv' and 'test_split.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the features dataset\n",
    "features_df = pd.read_csv('data_features.csv')\n",
    "\n",
    "# Split the data into train and test based on user_id\n",
    "train_data = features_df[features_df['user_id'] <= 106]\n",
    "test_data = features_df[features_df['user_id'] >= 107]\n",
    "\n",
    "# Save the train and test datasets to separate CSV files\n",
    "train_data.to_csv('train.csv', index=False)\n",
    "test_data.to_csv('test.csv', index=False)\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(\"Train and test datasets saved as 'train_split.csv' and 'test_split.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e12867ef-ccde-4b8b-8503-3cf6bd22465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time_stamp', 'label', 'hand_3D_acceleration_6_x',\n",
      "       'hand_3D_acceleration_6_y', 'hand_3D_acceleration_6_z', 'user_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all column names in the DataFrame\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f68969-77c5-404a-a8b9-a01d7be42eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f63fc-099a-4097-ad38-853b4bb8abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
