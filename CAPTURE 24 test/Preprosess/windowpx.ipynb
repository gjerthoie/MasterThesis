{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9365e1a1-9885-427e-b160-02f7f879b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import skew, kurtosis, iqr, entropy\n",
    "from numpy.fft import fft\n",
    "\n",
    "# Define folder paths\n",
    "input_folder = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\properLabels'\n",
    "output_folder = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\properLabels\\cleaned_window'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80539a3e-4415-4d07-8fd2-87b41d2da07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'x', 'y', 'z', 'label', 'user_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define file to create windows for\n",
    "df = pd.read_csv(r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\properLabels\\P001.csv')\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4512116c-32d4-4ab6-b801-35ddb250b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'x', 'y', 'z', 'label', 'user_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if 'labels' in df.columns:\n",
    "    df = df.rename(columns={'labels': 'label'})\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d9b3c-d865-488f-9793-b1f357f6f2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "450b8c87-c47e-4dce-acac-99d0cbf2de60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'P7_window.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "window_size = 170  # Number of rows per window\n",
    "step_size = 30     # Step size for 80% overlap (150 * 0.2 = 30)\n",
    "\n",
    "# List to store the windows\n",
    "windows = []\n",
    "\n",
    "# Unique window ID counter\n",
    "window_id = 0\n",
    "\n",
    "# Group by user ID and activity label to avoid mixing data from different users or activities\n",
    "for label, group_data in df.groupby(['label']):\n",
    "    # Create windows of 150 rows with 80% overlap within each group\n",
    "    for start in range(0, len(group_data) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = group_data.iloc[start:end].copy()  # Create a copy of the window\n",
    "        window['window_id'] = window_id  # Assign a unique window_id to each window\n",
    "        windows.append(window)\n",
    "        window_id += 1  # Increment the window_id for the next window\n",
    "\n",
    "# Combine all windows into a single DataFrame\n",
    "windowed_data = pd.concat(windows, ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame with window IDs to a new CSV file\n",
    "\n",
    "print(\"CSV file 'P7_window.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2714-c8f3-477e-aedc-e73b47f07c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbca2786-d4ae-4c5d-8e3a-b01e3288f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163236"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the generated windowed data\n",
    "\n",
    "# Count the unique window IDs to determine the number of windows\n",
    "num_windows = windowed_data['window_id'].nunique()\n",
    "\n",
    "num_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c07253f-0bd5-44a3-b73d-d48b82a087ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      time         x         y         z    label  user_id  \\\n",
      "0  2016-05-21 08:17:58.080 -0.321666 -0.806220  0.599923  cycling        2   \n",
      "1  2016-05-21 08:17:58.090 -0.116712 -1.042174  0.648134  cycling        2   \n",
      "2  2016-05-21 08:17:58.100 -0.148243 -1.073634  0.632064  cycling        2   \n",
      "3  2016-05-21 08:17:58.110 -0.321666 -0.790490  0.423148  cycling        2   \n",
      "4  2016-05-21 08:17:58.120 -0.321666 -0.601727  0.374936  cycling        2   \n",
      "\n",
      "   window_id  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "print(windowed_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56d53ed8-c458-4c6e-8277-1a777f40df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, iqr, entropy\n",
    "from numpy.fft import fft\n",
    "\n",
    "def calculate_features(window):\n",
    "    features = {}\n",
    "    axes = {'x': 'Ax', 'y': 'Ay', 'z': 'Az'}\n",
    " \n",
    "    for axis in axes.keys():\n",
    "        data = window[axis]\n",
    "\n",
    "        # Handle NaN and infinite values\n",
    "        data = data.replace([np.inf, -np.inf], np.nan)  # Replace infinities if any\n",
    "        data = data.dropna()  # Drop NaN values\n",
    "        \n",
    "        if data.empty:\n",
    "            continue  # Skip this column if data is empty after handling NaN and infinities\n",
    "\n",
    "        # Time-domain features\n",
    "        features[f'{axes[axis]}_mean'] = np.mean(data)\n",
    "        features[f'{axes[axis]}_std'] = np.std(data)\n",
    "        features[f'{axes[axis]}_mad'] = np.mean(np.abs(data - np.mean(data)))\n",
    "        features[f'{axes[axis]}_max'] = np.max(data)\n",
    "        features[f'{axes[axis]}_min'] = np.min(data)\n",
    "        features[f'{axes[axis]}_sma'] = np.sum(np.abs(data)) / len(data)\n",
    "        features[f'{axes[axis]}_energy'] = np.sum(data ** 2) / len(data)\n",
    "        features[f'{axes[axis]}_iqr'] = iqr(data)\n",
    "\n",
    "        # Adjust histogram calculation for better handling\n",
    "        if len(data) > 0:\n",
    "            hist, _ = np.histogram(data.dropna(), bins=10)  # Ensure no NaN values are included\n",
    "            features[f'{axes[axis]}_entropy'] = entropy(hist + 1e-6) if np.sum(hist) > 0 else 0\n",
    "\n",
    "        # Frequency-domain features\n",
    "        freq_data = np.abs(fft(data))[:len(data) // 2]\n",
    "        features[f'{axes[axis]}_meanFreq'] = np.sum(freq_data * np.arange(len(freq_data))) / np.sum(freq_data)\n",
    "        features[f'{axes[axis]}_skewness'] = skew(data)\n",
    "        features[f'{axes[axis]}_kurtosis'] = kurtosis(data)\n",
    "        features[f'{axes[axis]}_maxInds'] = np.argmax(freq_data)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caec9fc0-eebd-4df0-aa56-f59efe8b8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gjert\\AppData\\Local\\Temp\\ipykernel_23060\\944918434.py:38: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  features[f'{axes[axis]}_skewness'] = skew(data)\n",
      "C:\\Users\\Gjert\\AppData\\Local\\Temp\\ipykernel_23060\\944918434.py:39: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  features[f'{axes[axis]}_kurtosis'] = kurtosis(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\properLabels\\cleaned_window\\all.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Process each window to calculate features\n",
    "for window in windows:\n",
    "    if not window.empty:\n",
    "        window_id = window['window_id'].iloc[0]  # Ensure 'window_id' is a column\n",
    "        label = window['label'].iloc[0]         # Ensure 'label' is a column\n",
    "        user_id = window['user_id'].iloc[0]     # <--- Capture user_id here\n",
    "\n",
    "        # Calculate features\n",
    "        features = calculate_features(window)\n",
    "        \n",
    "        # Add identifiers\n",
    "        features['window_id'] = window_id\n",
    "        features['label'] = label\n",
    "        features['user_id'] = user_id  # <--- Include user_id in the feature dictionary\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "# Convert the list of feature dictionaries to a DataFrame\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Save the features to a new CSV file\n",
    "output_path = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\properLabels\\cleaned_window\\P1.csv'\n",
    "features_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"CSV file '{output_path}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12867ef-ccde-4b8b-8503-3cf6bd22465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ax_mean', 'Ax_std', 'Ax_mad', 'Ax_max', 'Ax_min', 'Ax_sma',\n",
      "       'Ax_energy', 'Ax_iqr', 'Ax_entropy', 'Ax_meanFreq', 'Ax_skewness',\n",
      "       'Ax_kurtosis', 'Ax_maxInds', 'Ay_mean', 'Ay_std', 'Ay_mad', 'Ay_max',\n",
      "       'Ay_min', 'Ay_sma', 'Ay_energy', 'Ay_iqr', 'Ay_entropy', 'Ay_meanFreq',\n",
      "       'Ay_skewness', 'Ay_kurtosis', 'Ay_maxInds', 'Az_mean', 'Az_std',\n",
      "       'Az_mad', 'Az_max', 'Az_min', 'Az_sma', 'Az_energy', 'Az_iqr',\n",
      "       'Az_entropy', 'Az_meanFreq', 'Az_skewness', 'Az_kurtosis', 'Az_maxInds',\n",
      "       'window_id', 'label', 'user_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all column names in the DataFrame\n",
    "print(features_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f68969-77c5-404a-a8b9-a01d7be42eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f63fc-099a-4097-ad38-853b4bb8abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3706ed-4f57-491c-b754-014ed9bb3980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2c935-1360-4b09-9906-11499b18fbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeee2d1-aeb0-46b0-a786-8aef74361404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b93c0c-358a-4814-afb1-556945909b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
