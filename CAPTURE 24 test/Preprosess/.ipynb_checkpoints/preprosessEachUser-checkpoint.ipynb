{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d69373b-21e8-4f2f-ae2e-3464ae592e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98b3fc4-0954-41a6-8982-c98264424c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement gzip (from versions: none)\n",
      "ERROR: No matching distribution found for gzip\n"
     ]
    }
   ],
   "source": [
    "pip install gzip shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b371f14-ee86-42b9-aa4e-be59cce5e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted P001.csv.gz to CSV.\n",
      "Converted P002.csv.gz to CSV.\n",
      "Converted P003.csv.gz to CSV.\n",
      "Converted P004.csv.gz to CSV.\n",
      "Converted P005.csv.gz to CSV.\n",
      "Converted P006.csv.gz to CSV.\n",
      "Converted P007.csv.gz to CSV.\n",
      "Converted P008.csv.gz to CSV.\n",
      "Converted P009.csv.gz to CSV.\n",
      "Converted P010.csv.gz to CSV.\n",
      "Converted P011.csv.gz to CSV.\n",
      "Converted P012.csv.gz to CSV.\n",
      "Converted P013.csv.gz to CSV.\n",
      "Converted P014.csv.gz to CSV.\n",
      "Converted P015.csv.gz to CSV.\n",
      "Converted P016.csv.gz to CSV.\n",
      "Converted P017.csv.gz to CSV.\n",
      "Converted P018.csv.gz to CSV.\n",
      "Converted P019.csv.gz to CSV.\n",
      "Converted P020.csv.gz to CSV.\n",
      "Converted P021.csv.gz to CSV.\n",
      "Converted P022.csv.gz to CSV.\n",
      "Converted P023.csv.gz to CSV.\n",
      "Converted P024.csv.gz to CSV.\n",
      "Converted P025.csv.gz to CSV.\n",
      "Converted P026.csv.gz to CSV.\n",
      "Converted P027.csv.gz to CSV.\n",
      "Converted P028.csv.gz to CSV.\n",
      "Converted P029.csv.gz to CSV.\n",
      "Converted P030.csv.gz to CSV.\n",
      "Converted P031.csv.gz to CSV.\n",
      "Converted P032.csv.gz to CSV.\n",
      "Converted P033.csv.gz to CSV.\n",
      "Converted P034.csv.gz to CSV.\n",
      "Converted P035.csv.gz to CSV.\n",
      "Converted P036.csv.gz to CSV.\n",
      "Converted P037.csv.gz to CSV.\n",
      "Converted P038.csv.gz to CSV.\n",
      "Converted P039.csv.gz to CSV.\n",
      "Converted P040.csv.gz to CSV.\n",
      "Converted P041.csv.gz to CSV.\n",
      "Converted P042.csv.gz to CSV.\n",
      "Converted P043.csv.gz to CSV.\n",
      "Converted P044.csv.gz to CSV.\n",
      "Converted P045.csv.gz to CSV.\n",
      "Converted P046.csv.gz to CSV.\n",
      "Converted P047.csv.gz to CSV.\n",
      "Converted P048.csv.gz to CSV.\n",
      "Converted P049.csv.gz to CSV.\n",
      "Converted P050.csv.gz to CSV.\n",
      "Converted P051.csv.gz to CSV.\n",
      "Converted P052.csv.gz to CSV.\n",
      "Converted P053.csv.gz to CSV.\n",
      "Converted P054.csv.gz to CSV.\n",
      "Converted P055.csv.gz to CSV.\n",
      "Converted P056.csv.gz to CSV.\n",
      "Converted P057.csv.gz to CSV.\n",
      "Converted P058.csv.gz to CSV.\n",
      "Converted P059.csv.gz to CSV.\n",
      "Converted P060.csv.gz to CSV.\n",
      "Converted P061.csv.gz to CSV.\n",
      "Converted P062.csv.gz to CSV.\n",
      "Converted P063.csv.gz to CSV.\n",
      "Converted P064.csv.gz to CSV.\n",
      "Converted P065.csv.gz to CSV.\n",
      "Converted P066.csv.gz to CSV.\n",
      "Converted P067.csv.gz to CSV.\n",
      "Converted P068.csv.gz to CSV.\n",
      "Converted P069.csv.gz to CSV.\n",
      "Converted P070.csv.gz to CSV.\n",
      "Converted P071.csv.gz to CSV.\n",
      "Converted P072.csv.gz to CSV.\n",
      "Converted P073.csv.gz to CSV.\n",
      "Converted P074.csv.gz to CSV.\n",
      "Converted P075.csv.gz to CSV.\n",
      "Converted P076.csv.gz to CSV.\n",
      "Converted P077.csv.gz to CSV.\n",
      "Converted P078.csv.gz to CSV.\n",
      "Converted P079.csv.gz to CSV.\n",
      "Converted P080.csv.gz to CSV.\n",
      "Converted P081.csv.gz to CSV.\n",
      "Converted P082.csv.gz to CSV.\n",
      "Converted P083.csv.gz to CSV.\n",
      "Converted P084.csv.gz to CSV.\n",
      "Converted P085.csv.gz to CSV.\n",
      "Converted P086.csv.gz to CSV.\n",
      "Converted P087.csv.gz to CSV.\n",
      "Converted P088.csv.gz to CSV.\n",
      "Converted P089.csv.gz to CSV.\n",
      "Converted P090.csv.gz to CSV.\n",
      "Converted P091.csv.gz to CSV.\n",
      "Converted P092.csv.gz to CSV.\n",
      "Converted P093.csv.gz to CSV.\n",
      "Converted P094.csv.gz to CSV.\n",
      "Converted P095.csv.gz to CSV.\n",
      "Converted P096.csv.gz to CSV.\n",
      "Converted P097.csv.gz to CSV.\n",
      "Converted P098.csv.gz to CSV.\n",
      "Converted P099.csv.gz to CSV.\n",
      "Converted P100.csv.gz to CSV.\n",
      "Converted P101.csv.gz to CSV.\n",
      "Converted P102.csv.gz to CSV.\n",
      "Converted P103.csv.gz to CSV.\n",
      "Converted P104.csv.gz to CSV.\n",
      "Converted P105.csv.gz to CSV.\n",
      "Converted P106.csv.gz to CSV.\n",
      "Converted P107.csv.gz to CSV.\n",
      "Converted P108.csv.gz to CSV.\n",
      "Converted P109.csv.gz to CSV.\n",
      "Converted P110.csv.gz to CSV.\n",
      "Converted P111.csv.gz to CSV.\n",
      "Converted P112.csv.gz to CSV.\n",
      "Converted P113.csv.gz to CSV.\n",
      "Converted P114.csv.gz to CSV.\n",
      "Converted P115.csv.gz to CSV.\n",
      "Converted P116.csv.gz to CSV.\n",
      "Converted P117.csv.gz to CSV.\n",
      "Converted P118.csv.gz to CSV.\n",
      "Converted P119.csv.gz to CSV.\n",
      "Converted P120.csv.gz to CSV.\n",
      "Converted P121.csv.gz to CSV.\n",
      "Converted P122.csv.gz to CSV.\n",
      "Converted P123.csv.gz to CSV.\n",
      "Converted P124.csv.gz to CSV.\n",
      "Converted P125.csv.gz to CSV.\n",
      "Converted P126.csv.gz to CSV.\n",
      "Converted P127.csv.gz to CSV.\n",
      "Converted P128.csv.gz to CSV.\n",
      "Converted P129.csv.gz to CSV.\n",
      "Converted P130.csv.gz to CSV.\n",
      "Converted P131.csv.gz to CSV.\n",
      "Converted P132.csv.gz to CSV.\n",
      "Converted P133.csv.gz to CSV.\n",
      "Converted P134.csv.gz to CSV.\n",
      "Converted P135.csv.gz to CSV.\n",
      "Converted P136.csv.gz to CSV.\n",
      "Converted P137.csv.gz to CSV.\n",
      "Converted P138.csv.gz to CSV.\n",
      "Converted P139.csv.gz to CSV.\n",
      "Converted P140.csv.gz to CSV.\n",
      "Converted P141.csv.gz to CSV.\n",
      "Converted P142.csv.gz to CSV.\n",
      "Converted P143.csv.gz to CSV.\n",
      "Converted P144.csv.gz to CSV.\n",
      "Converted P145.csv.gz to CSV.\n",
      "Converted P146.csv.gz to CSV.\n",
      "Converted P147.csv.gz to CSV.\n",
      "Converted P148.csv.gz to CSV.\n",
      "Converted P149.csv.gz to CSV.\n",
      "Converted P150.csv.gz to CSV.\n",
      "Converted P151.csv.gz to CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Set the directory path where the .gz files are located\n",
    "directory_path = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter for .gz files\n",
    "gz_files = [f for f in files if f.endswith('.gz')]\n",
    "\n",
    "# Process each file\n",
    "for file_name in gz_files:\n",
    "    # Full path to the compressed file\n",
    "    gz_path = os.path.join(directory_path, file_name)\n",
    "    # Destination path for the decompressed file\n",
    "    csv_path = os.path.join(directory_path, file_name[:-3])  # Remove'.gz' extension\n",
    "\n",
    "    # Open the compressed file and create a new uncompressed file\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(csv_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    print(f\"Converted {file_name} to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a41981-7ac1-41d0-ace3-ced65f818e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted P001.csv.gz.\n",
      "Deleted P002.csv.gz.\n",
      "Deleted P003.csv.gz.\n",
      "Deleted P004.csv.gz.\n",
      "Deleted P005.csv.gz.\n",
      "Deleted P006.csv.gz.\n",
      "Deleted P007.csv.gz.\n",
      "Deleted P008.csv.gz.\n",
      "Deleted P009.csv.gz.\n",
      "Deleted P010.csv.gz.\n",
      "Deleted P011.csv.gz.\n",
      "Deleted P012.csv.gz.\n",
      "Deleted P013.csv.gz.\n",
      "Deleted P014.csv.gz.\n",
      "Deleted P015.csv.gz.\n",
      "Deleted P016.csv.gz.\n",
      "Deleted P017.csv.gz.\n",
      "Deleted P018.csv.gz.\n",
      "Deleted P019.csv.gz.\n",
      "Deleted P020.csv.gz.\n",
      "Deleted P021.csv.gz.\n",
      "Deleted P022.csv.gz.\n",
      "Deleted P023.csv.gz.\n",
      "Deleted P024.csv.gz.\n",
      "Deleted P025.csv.gz.\n",
      "Deleted P026.csv.gz.\n",
      "Deleted P027.csv.gz.\n",
      "Deleted P028.csv.gz.\n",
      "Deleted P029.csv.gz.\n",
      "Deleted P030.csv.gz.\n",
      "Deleted P031.csv.gz.\n",
      "Deleted P032.csv.gz.\n",
      "Deleted P033.csv.gz.\n",
      "Deleted P034.csv.gz.\n",
      "Deleted P035.csv.gz.\n",
      "Deleted P036.csv.gz.\n",
      "Deleted P037.csv.gz.\n",
      "Deleted P038.csv.gz.\n",
      "Deleted P039.csv.gz.\n",
      "Deleted P040.csv.gz.\n",
      "Deleted P041.csv.gz.\n",
      "Deleted P042.csv.gz.\n",
      "Deleted P043.csv.gz.\n",
      "Deleted P044.csv.gz.\n",
      "Deleted P045.csv.gz.\n",
      "Deleted P046.csv.gz.\n",
      "Deleted P047.csv.gz.\n",
      "Deleted P048.csv.gz.\n",
      "Deleted P049.csv.gz.\n",
      "Deleted P050.csv.gz.\n",
      "Deleted P051.csv.gz.\n",
      "Deleted P052.csv.gz.\n",
      "Deleted P053.csv.gz.\n",
      "Deleted P054.csv.gz.\n",
      "Deleted P055.csv.gz.\n",
      "Deleted P056.csv.gz.\n",
      "Deleted P057.csv.gz.\n",
      "Deleted P058.csv.gz.\n",
      "Deleted P059.csv.gz.\n",
      "Deleted P060.csv.gz.\n",
      "Deleted P061.csv.gz.\n",
      "Deleted P062.csv.gz.\n",
      "Deleted P063.csv.gz.\n",
      "Deleted P064.csv.gz.\n",
      "Deleted P065.csv.gz.\n",
      "Deleted P066.csv.gz.\n",
      "Deleted P067.csv.gz.\n",
      "Deleted P068.csv.gz.\n",
      "Deleted P069.csv.gz.\n",
      "Deleted P070.csv.gz.\n",
      "Deleted P071.csv.gz.\n",
      "Deleted P072.csv.gz.\n",
      "Deleted P073.csv.gz.\n",
      "Deleted P074.csv.gz.\n",
      "Deleted P075.csv.gz.\n",
      "Deleted P076.csv.gz.\n",
      "Deleted P077.csv.gz.\n",
      "Deleted P078.csv.gz.\n",
      "Deleted P079.csv.gz.\n",
      "Deleted P080.csv.gz.\n",
      "Deleted P081.csv.gz.\n",
      "Deleted P082.csv.gz.\n",
      "Deleted P083.csv.gz.\n",
      "Deleted P084.csv.gz.\n",
      "Deleted P085.csv.gz.\n",
      "Deleted P086.csv.gz.\n",
      "Deleted P087.csv.gz.\n",
      "Deleted P088.csv.gz.\n",
      "Deleted P089.csv.gz.\n",
      "Deleted P090.csv.gz.\n",
      "Deleted P091.csv.gz.\n",
      "Deleted P092.csv.gz.\n",
      "Deleted P093.csv.gz.\n",
      "Deleted P094.csv.gz.\n",
      "Deleted P095.csv.gz.\n",
      "Deleted P096.csv.gz.\n",
      "Deleted P097.csv.gz.\n",
      "Deleted P098.csv.gz.\n",
      "Deleted P099.csv.gz.\n",
      "Deleted P100.csv.gz.\n",
      "Deleted P101.csv.gz.\n",
      "Deleted P102.csv.gz.\n",
      "Deleted P103.csv.gz.\n",
      "Deleted P104.csv.gz.\n",
      "Deleted P105.csv.gz.\n",
      "Deleted P106.csv.gz.\n",
      "Deleted P107.csv.gz.\n",
      "Deleted P108.csv.gz.\n",
      "Deleted P109.csv.gz.\n",
      "Deleted P110.csv.gz.\n",
      "Deleted P111.csv.gz.\n",
      "Deleted P112.csv.gz.\n",
      "Deleted P113.csv.gz.\n",
      "Deleted P114.csv.gz.\n",
      "Deleted P115.csv.gz.\n",
      "Deleted P116.csv.gz.\n",
      "Deleted P117.csv.gz.\n",
      "Deleted P118.csv.gz.\n",
      "Deleted P119.csv.gz.\n",
      "Deleted P120.csv.gz.\n",
      "Deleted P121.csv.gz.\n",
      "Deleted P122.csv.gz.\n",
      "Deleted P123.csv.gz.\n",
      "Deleted P124.csv.gz.\n",
      "Deleted P125.csv.gz.\n",
      "Deleted P126.csv.gz.\n",
      "Deleted P127.csv.gz.\n",
      "Deleted P128.csv.gz.\n",
      "Deleted P129.csv.gz.\n",
      "Deleted P130.csv.gz.\n",
      "Deleted P131.csv.gz.\n",
      "Deleted P132.csv.gz.\n",
      "Deleted P133.csv.gz.\n",
      "Deleted P134.csv.gz.\n",
      "Deleted P135.csv.gz.\n",
      "Deleted P136.csv.gz.\n",
      "Deleted P137.csv.gz.\n",
      "Deleted P138.csv.gz.\n",
      "Deleted P139.csv.gz.\n",
      "Deleted P140.csv.gz.\n",
      "Deleted P141.csv.gz.\n",
      "Deleted P142.csv.gz.\n",
      "Deleted P143.csv.gz.\n",
      "Deleted P144.csv.gz.\n",
      "Deleted P145.csv.gz.\n",
      "Deleted P146.csv.gz.\n",
      "Deleted P147.csv.gz.\n",
      "Deleted P148.csv.gz.\n",
      "Deleted P149.csv.gz.\n",
      "Deleted P150.csv.gz.\n",
      "Deleted P151.csv.gz.\n"
     ]
    }
   ],
   "source": [
    "# Filter for .gz files and delete them\n",
    "for file_name in files:\n",
    "    if file_name.endswith('.gz'):\n",
    "        gz_path = os.path.join(directory_path, file_name)\n",
    "        os.remove(gz_path)\n",
    "        print(f\"Deleted {file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd20219c-4964-47a2-bb1c-532e33b93e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gjert\\AppData\\Local\\Temp\\ipykernel_27732\\1480407050.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\P001.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         time        x         y         z  \\\n",
      "0  2016-11-13 02:18:00.000000 -0.46669 -0.533341  0.658472   \n",
      "1  2016-11-13 02:18:00.010000 -0.46669 -0.533341  0.658472   \n",
      "2  2016-11-13 02:18:00.020000 -0.46669 -0.533341  0.658472   \n",
      "3  2016-11-13 02:18:00.030000 -0.46669 -0.533341  0.658472   \n",
      "4  2016-11-13 02:18:00.040000 -0.46669 -0.533341  0.658472   \n",
      "\n",
      "               annotation  \n",
      "0  7030 sleeping;MET 0.95  \n",
      "1  7030 sleeping;MET 0.95  \n",
      "2  7030 sleeping;MET 0.95  \n",
      "3  7030 sleeping;MET 0.95  \n",
      "4  7030 sleeping;MET 0.95  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file and print the first few rows to verify\n",
    "directory_path = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24'\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\P001.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf5a6abd-c427-4a67-b282-3e9bbb5d60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gjert\\AppData\\Local\\Temp\\ipykernel_27732\\2233730405.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dc = pd.read_csv(r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\P001.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 10020001\n"
     ]
    }
   ],
   "source": [
    "dc = pd.read_csv(r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24\\P001.csv')\n",
    "num_rows = dc.shape[0]\n",
    "\n",
    "# Print the number of rows in the DataFrame\n",
    "print(\"Number of rows in the DataFrame:\", num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6b86eaa-6b09-4e94-9341-c5107ed28688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'x', 'y', 'z', 'annotation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67d3c0bd-51c3-46b3-b745-b3e8d688f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7030 sleeping;MET 0.95' nan\n",
      " 'home activity;self care;13020 dressing/undressing;MET 2.5'\n",
      " 'home activity;miscellaneous;walking;17150 walking household without observable loads;MET 2.0'\n",
      " 'home activity;household chores;preparing meals/cooking/washing dishes;5035 kitchen activity general cooking/washing/dishes/cleaning up;MET 3.3'\n",
      " 'transportation;private transportation;16010 driving automobile or light truck (not a semi);MET 2.5'\n",
      " 'transportation;walking;17161 walking not as the single means of transports e.g.from house to transports or vice versa/from car to places or vice versa/between transports;MET 2.5'\n",
      " 'leisure;miscellaneous;standing;9050 standing talking in person/using a phone/smartphone/tablet;MET 1.8'\n",
      " 'transportation;waiting;7040 standing in a line;MET 1.3'\n",
      " 'leisure;miscellaneous;5060 shopping miscellaneous;MET 2.3'\n",
      " 'leisure;eating;13030 eating sitting indoor/outdoor;MET 1.5'\n",
      " 'transportation;walking;17250 walking as the single means to a destination not to work or class;MET 3.0'\n",
      " 'leisure;miscellaneous;standing;9020 standing writing/drawing/painting;MET 1.8'\n",
      " 'home activity;miscellaneous;sitting;11580 office work such as writing and typing (with or without eating at the same time);MET 1.5'\n",
      " 'home activity;eating;13030 eating sitting alone or with someone;MET 1.5'\n",
      " 'home activity;household chores;washing/ironing/mending clothes;5090 folding or hanging clothes/put clothes in or out of washer or dryer/packing suitcase limited walking;MET 2.0'\n",
      " 'home activity;household chores;house cleaning;furniture;5032 dusting or polishing furniture;MET 2.3'\n",
      " 'leisure;miscellaneous;sitting;9060 (generic) sitting/lying reading or without observable/identifiable activities;MET 1.3'\n",
      " 'leisure;miscellaneous;walking;21070 (generic) walking and occasional standing (no more than two consecutive images);MET 2.5'\n",
      " 'home activity;miscellaneous;sitting;9030  sitting desk work (with or without eating at the same time);MET 1.3'\n",
      " 'transportation;waiting;7021 sitting;MET 1.3'\n",
      " 'mixed-activity;sitstand+activity;MET 2.0'\n",
      " 'leisure;miscellaneous;sitting;5080 sitting non-desk work (with or without eating at the same time);MET 1.3'\n",
      " 'home activity;miscellaneous;standing;9050 standing talking in person on the phone/computer (skype chatting) or using a mobileo phone/smartphone/tablet;MET 1.8'\n",
      " 'home activity;miscellaneous;sitting;9055 sitting/lying talking in person/using a mobile phone/smartphone/tablet or talking on the phone/computer (skype chatting);MET 1.5'\n",
      " 'home activity;leisure;activties for maintenance of a household;miscellaneous;9100 retreat/family reunion activities involving sitting eating relaxing talking with more than one person;MET 1.8'\n",
      " 'home activity;child/elderly/pet care;child care;5185 child care sitting/kneeling;MET 2.0'\n",
      " 'home activity;miscellaneous;walking;5147 walking moving away light items (pens/papers/keys not included);MET 3.0'\n",
      " 'leisure;miscellaneous;standing;9070 standing reading or without observable/identifiable activities;MET 1.8'\n",
      " 'home activity;miscellaneous;sitting;21010 sitting non-desk work (with or without eating at the same time);MET 2.5']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values in the 'labels' column\n",
    "unique_labels = df['annotation'].unique()\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0539756c-d62a-4e74-8e8d-6cd40fc81227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create activity labels to map the activities to\n",
    "activity_map = {\n",
    "    0: 'transient',\n",
    "    1: 'lying',\n",
    "    2: 'sitting',\n",
    "    3: 'standing',\n",
    "    4: 'walking',\n",
    "    5: 'running',\n",
    "    6: 'cycling',\n",
    "    7: 'Nordic_walking',\n",
    "    9: 'watching_TV',\n",
    "    10: 'computer_work',\n",
    "    11: 'car driving',\n",
    "    12: 'ascending_stairs',\n",
    "    13: 'descending_stairs',\n",
    "    16: 'vacuum_cleaning',\n",
    "    17: 'ironing',\n",
    "    18: 'folding_laundry',\n",
    "    19: 'house_cleaning',\n",
    "    20: 'playing_soccer',\n",
    "    24: 'rope_jumping'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29481cbb-ed1d-46c5-969c-d8eb449e55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_activity(label):\n",
    "    # Check if the label is a string\n",
    "    if isinstance(label, str):\n",
    "        # Normalize the label to lowercase to simplify matching\n",
    "        label = label.lower()\n",
    "        if 'walking' in label:\n",
    "            if 'stairs' in label:\n",
    "                return activity_map[12] if 'ascending' in label else activity_map[13]\n",
    "            return activity_map[4]\n",
    "        elif 'sitting' in label:\n",
    "            if 'car' in label or 'driving' in label:\n",
    "                return activity_map[11]\n",
    "            elif 'computer' in label:\n",
    "                return activity_map[10]\n",
    "            return activity_map[2]\n",
    "        elif 'standing' in label:\n",
    "            return activity_map[3]\n",
    "        elif 'running' in label:\n",
    "            return activity_map[5]\n",
    "        elif 'cycling' in label or 'biking' in label:\n",
    "            return activity_map[6]\n",
    "        elif 'cleaning' in label:\n",
    "            if 'vacuum' in label:\n",
    "                return activity_map[16]\n",
    "            return activity_map[19]\n",
    "        elif 'ironing' in label:\n",
    "            return activity_map[17]\n",
    "        elif 'folding' in label:\n",
    "            return activity_map[18]\n",
    "        elif 'lying' in label or 'sleeping' in label:\n",
    "            return activity_map[1]\n",
    "        # Add more rules as necessary\n",
    "    return 'unknown'  # Default case if label is not a string or no other matches found\n",
    "\n",
    "# Apply the classification function to each label in the DataFrame\n",
    "df['mapped_category'] = df['annotation'].apply(classify_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee34ada7-c05b-4303-9aff-474ad9c1186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying' 'unknown' 'walking' 'house_cleaning' 'standing' 'sitting'\n",
      " 'computer_work' 'car driving']\n"
     ]
    }
   ],
   "source": [
    "unique_mapped_categories = df['mapped_category'].unique()\n",
    "\n",
    "# Print the unique mapped categories\n",
    "print(unique_mapped_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90a4f5e5-dbf5-4d79-8e13-203f86eda4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                time         x         y         z  \\\n",
      "0         2016-11-13 02:18:00.000000 -0.466690 -0.533341  0.658472   \n",
      "1         2016-11-13 02:18:00.010000 -0.466690 -0.533341  0.658472   \n",
      "2         2016-11-13 02:18:00.020000 -0.466690 -0.533341  0.658472   \n",
      "3         2016-11-13 02:18:00.030000 -0.466690 -0.533341  0.658472   \n",
      "4         2016-11-13 02:18:00.040000 -0.466690 -0.533341  0.658472   \n",
      "...                              ...       ...       ...       ...   \n",
      "10019996  2016-11-14 06:07:59.960000  0.049416 -0.797846  0.565700   \n",
      "10019997  2016-11-14 06:07:59.970000  0.049416 -0.782285  0.565700   \n",
      "10019998  2016-11-14 06:07:59.980000  0.049416 -0.782285  0.565700   \n",
      "10019999  2016-11-14 06:07:59.990000  0.049416 -0.782285  0.565700   \n",
      "10020000  2016-11-14 06:08:00.000000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                      annotation  \n",
      "0         7030 sleeping;MET 0.95  \n",
      "1         7030 sleeping;MET 0.95  \n",
      "2         7030 sleeping;MET 0.95  \n",
      "3         7030 sleeping;MET 0.95  \n",
      "4         7030 sleeping;MET 0.95  \n",
      "...                          ...  \n",
      "10019996  7030 sleeping;MET 0.95  \n",
      "10019997  7030 sleeping;MET 0.95  \n",
      "10019998  7030 sleeping;MET 0.95  \n",
      "10019999  7030 sleeping;MET 0.95  \n",
      "10020000  7030 sleeping;MET 0.95  \n",
      "\n",
      "[10020001 rows x 5 columns]\n",
      "\n",
      "DataFrame after removing rows with 'unknown':\n",
      "                                time         x         y         z  \\\n",
      "0         2016-11-13 02:18:00.000000 -0.466690 -0.533341  0.658472   \n",
      "1         2016-11-13 02:18:00.010000 -0.466690 -0.533341  0.658472   \n",
      "2         2016-11-13 02:18:00.020000 -0.466690 -0.533341  0.658472   \n",
      "3         2016-11-13 02:18:00.030000 -0.466690 -0.533341  0.658472   \n",
      "4         2016-11-13 02:18:00.040000 -0.466690 -0.533341  0.658472   \n",
      "...                              ...       ...       ...       ...   \n",
      "10019996  2016-11-14 06:07:59.960000  0.049416 -0.797846  0.565700   \n",
      "10019997  2016-11-14 06:07:59.970000  0.049416 -0.782285  0.565700   \n",
      "10019998  2016-11-14 06:07:59.980000  0.049416 -0.782285  0.565700   \n",
      "10019999  2016-11-14 06:07:59.990000  0.049416 -0.782285  0.565700   \n",
      "10020000  2016-11-14 06:08:00.000000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                      annotation mapped_category  \n",
      "0         7030 sleeping;MET 0.95           lying  \n",
      "1         7030 sleeping;MET 0.95           lying  \n",
      "2         7030 sleeping;MET 0.95           lying  \n",
      "3         7030 sleeping;MET 0.95           lying  \n",
      "4         7030 sleeping;MET 0.95           lying  \n",
      "...                          ...             ...  \n",
      "10019996  7030 sleeping;MET 0.95           lying  \n",
      "10019997  7030 sleeping;MET 0.95           lying  \n",
      "10019998  7030 sleeping;MET 0.95           lying  \n",
      "10019999  7030 sleeping;MET 0.95           lying  \n",
      "10020000  7030 sleeping;MET 0.95           lying  \n",
      "\n",
      "[6152103 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial DataFrame:\")\n",
    "print(dc)\n",
    "# Remove rows that contain 'unknown'\n",
    "df = df[~df.isin(['unknown']).any(axis=1)]\n",
    "df = df[~df.isin(['car driving']).any(axis=1)]\n",
    "df = df[~df.isin(['computer_work']).any(axis=1)]\n",
    "# Display the DataFrame after removing rows with 'unknown'\n",
    "print(\"\\nDataFrame after removing rows with 'unknown':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "369d9efe-5882-4f33-aafb-642fdd48a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying' 'walking' 'house_cleaning' 'standing' 'sitting']\n"
     ]
    }
   ],
   "source": [
    "unique_mapped_categories = df['mapped_category'].unique()\n",
    "\n",
    "# Print the unique mapped categories\n",
    "print(unique_mapped_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b72d475d-b46f-4530-b72f-a4035d6676d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows categorized as 'lying': 44.57%\n",
      "Percentage of rows categorized as 'sitting': 31.73%\n",
      "Percentage of rows categorized as 'walking': 10.01%\n",
      "Percentage of rows categorized as 'house cleaning': 11.88%\n",
      "Percentage of rows categorized as 'standing': 1.80%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentages for each category\n",
    "percentage_lying = 100 * (df['mapped_category'] == 'lying').mean()\n",
    "percentage_sitting = 100 * (df['mapped_category'] == 'sitting').mean()\n",
    "percentage_walking = 100 * (df['mapped_category'] == 'walking').mean()\n",
    "percentage_house_cleaning = 100 * (df['mapped_category'] == 'house_cleaning').mean()\n",
    "percentage_standing = 100 * (df['mapped_category'] == 'standing').mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of rows categorized as 'lying': {percentage_lying:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'sitting': {percentage_sitting:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'walking': {percentage_walking:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'house cleaning': {percentage_house_cleaning:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'standing': {percentage_standing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3eb1cb66-23b5-4e5c-8bb6-66cd8d3b4f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The house cleaning activities have been saved to 'house_cleaning_activities.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter the DataFrame for rows where 'mapped_category' is 'house_cleaning'\n",
    "house_cleaning_df = df[df['mapped_category'] == 'house_cleaning']\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "house_cleaning_df.to_csv('house_cleaning_activities.csv', index=False)\n",
    "\n",
    "print(\"The house cleaning activities have been saved to 'house_cleaning_activities.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ee87243-8abb-4680-8b8d-2fb1b0bd7be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                time         x         y         z  \\\n",
      "0         2016-11-13 02:18:00.000000 -0.466690 -0.533341  0.658472   \n",
      "1         2016-11-13 02:18:00.010000 -0.466690 -0.533341  0.658472   \n",
      "2         2016-11-13 02:18:00.020000 -0.466690 -0.533341  0.658472   \n",
      "3         2016-11-13 02:18:00.030000 -0.466690 -0.533341  0.658472   \n",
      "4         2016-11-13 02:18:00.040000 -0.466690 -0.533341  0.658472   \n",
      "...                              ...       ...       ...       ...   \n",
      "10019996  2016-11-14 06:07:59.960000  0.049416 -0.797846  0.565700   \n",
      "10019997  2016-11-14 06:07:59.970000  0.049416 -0.782285  0.565700   \n",
      "10019998  2016-11-14 06:07:59.980000  0.049416 -0.782285  0.565700   \n",
      "10019999  2016-11-14 06:07:59.990000  0.049416 -0.782285  0.565700   \n",
      "10020000  2016-11-14 06:08:00.000000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                      annotation mapped_category  \n",
      "0         7030 sleeping;MET 0.95           lying  \n",
      "1         7030 sleeping;MET 0.95           lying  \n",
      "2         7030 sleeping;MET 0.95           lying  \n",
      "3         7030 sleeping;MET 0.95           lying  \n",
      "4         7030 sleeping;MET 0.95           lying  \n",
      "...                          ...             ...  \n",
      "10019996  7030 sleeping;MET 0.95           lying  \n",
      "10019997  7030 sleeping;MET 0.95           lying  \n",
      "10019998  7030 sleeping;MET 0.95           lying  \n",
      "10019999  7030 sleeping;MET 0.95           lying  \n",
      "10020000  7030 sleeping;MET 0.95           lying  \n",
      "\n",
      "[6152103 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[~df['mapped_category'].isin(['unknown', 'other_flag'])]\n",
    "\n",
    "# Printing the filtered DataFrame\n",
    "print(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de0f23f8-fce6-4fee-ae89-3c3b8713b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 6152103\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "\n",
    "# Print the number of rows in the DataFrame\n",
    "print(\"Number of rows in the DataFrame:\", num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6fdb3c20-351d-4862-bd5a-75672fc7314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                time         x         y         z  \\\n",
      "0         2016-11-13 02:18:00.000000 -0.466690 -0.533341  0.658472   \n",
      "1         2016-11-13 02:18:00.010000 -0.466690 -0.533341  0.658472   \n",
      "2         2016-11-13 02:18:00.020000 -0.466690 -0.533341  0.658472   \n",
      "3         2016-11-13 02:18:00.030000 -0.466690 -0.533341  0.658472   \n",
      "4         2016-11-13 02:18:00.040000 -0.466690 -0.533341  0.658472   \n",
      "...                              ...       ...       ...       ...   \n",
      "10019996  2016-11-14 06:07:59.960000  0.049416 -0.797846  0.565700   \n",
      "10019997  2016-11-14 06:07:59.970000  0.049416 -0.782285  0.565700   \n",
      "10019998  2016-11-14 06:07:59.980000  0.049416 -0.782285  0.565700   \n",
      "10019999  2016-11-14 06:07:59.990000  0.049416 -0.782285  0.565700   \n",
      "10020000  2016-11-14 06:08:00.000000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                          labels mapped_category  \n",
      "0         7030 sleeping;MET 0.95           lying  \n",
      "1         7030 sleeping;MET 0.95           lying  \n",
      "2         7030 sleeping;MET 0.95           lying  \n",
      "3         7030 sleeping;MET 0.95           lying  \n",
      "4         7030 sleeping;MET 0.95           lying  \n",
      "...                          ...             ...  \n",
      "10019996  7030 sleeping;MET 0.95           lying  \n",
      "10019997  7030 sleeping;MET 0.95           lying  \n",
      "10019998  7030 sleeping;MET 0.95           lying  \n",
      "10019999  7030 sleeping;MET 0.95           lying  \n",
      "10020000  7030 sleeping;MET 0.95           lying  \n",
      "\n",
      "[6152103 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "\n",
    "\n",
    "# Renaming the 'annotation' column to 'labels'\n",
    "df = df.rename(columns={'annotation': 'labels'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "538d0669-f32a-4001-bec3-c2374dfe16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            time         x         y         z  \\\n",
      "0        2016-11-13 02:18:00.000 -0.466690 -0.533341  0.658472   \n",
      "1        2016-11-13 02:18:00.010 -0.466690 -0.533341  0.658472   \n",
      "2        2016-11-13 02:18:00.020 -0.466690 -0.533341  0.658472   \n",
      "3        2016-11-13 02:18:00.030 -0.466690 -0.533341  0.658472   \n",
      "4        2016-11-13 02:18:00.040 -0.466690 -0.533341  0.658472   \n",
      "...                          ...       ...       ...       ...   \n",
      "10019996 2016-11-14 06:07:59.960  0.049416 -0.797846  0.565700   \n",
      "10019997 2016-11-14 06:07:59.970  0.049416 -0.782285  0.565700   \n",
      "10019998 2016-11-14 06:07:59.980  0.049416 -0.782285  0.565700   \n",
      "10019999 2016-11-14 06:07:59.990  0.049416 -0.782285  0.565700   \n",
      "10020000 2016-11-14 06:08:00.000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                          labels mapped_category           category_time  \\\n",
      "0         7030 sleeping;MET 0.95           lying 2016-11-13 02:18:00.000   \n",
      "1         7030 sleeping;MET 0.95           lying 2016-11-13 02:18:00.010   \n",
      "2         7030 sleeping;MET 0.95           lying 2016-11-13 02:18:00.020   \n",
      "3         7030 sleeping;MET 0.95           lying 2016-11-13 02:18:00.030   \n",
      "4         7030 sleeping;MET 0.95           lying 2016-11-13 02:18:00.040   \n",
      "...                          ...             ...                     ...   \n",
      "10019996  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.960   \n",
      "10019997  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.970   \n",
      "10019998  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.980   \n",
      "10019999  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.990   \n",
      "10020000  7030 sleeping;MET 0.95           lying 2016-11-14 06:08:00.000   \n",
      "\n",
      "         formatted_time  \n",
      "0              02:18:00  \n",
      "1              02:18:00  \n",
      "2              02:18:00  \n",
      "3              02:18:00  \n",
      "4              02:18:00  \n",
      "...                 ...  \n",
      "10019996       06:07:59  \n",
      "10019997       06:07:59  \n",
      "10019998       06:07:59  \n",
      "10019999       06:07:59  \n",
      "10020000       06:08:00  \n",
      "\n",
      "[6152103 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Format the datetime column to 'HH:MM:SS' only\n",
    "df['formatted_time'] = df['time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "47ab7926-a235-493f-b85a-cfb39150165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gjert\\AppData\\Local\\Temp\\ipykernel_27732\\1725305993.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['formatted_time'] = pd.to_datetime(df['formatted_time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            time         x         y         z  \\\n",
      "1332000  2016-11-13 06:00:00.000 -0.310256  0.073548 -0.958022   \n",
      "1332001  2016-11-13 06:00:00.010 -0.310256  0.057986 -0.958022   \n",
      "1332002  2016-11-13 06:00:00.020 -0.310256  0.057986 -0.958022   \n",
      "1332003  2016-11-13 06:00:00.030 -0.310256  0.073548 -0.958022   \n",
      "1332004  2016-11-13 06:00:00.040 -0.310256  0.057986 -0.958022   \n",
      "...                          ...       ...       ...       ...   \n",
      "10019996 2016-11-14 06:07:59.960  0.049416 -0.797846  0.565700   \n",
      "10019997 2016-11-14 06:07:59.970  0.049416 -0.782285  0.565700   \n",
      "10019998 2016-11-14 06:07:59.980  0.049416 -0.782285  0.565700   \n",
      "10019999 2016-11-14 06:07:59.990  0.049416 -0.782285  0.565700   \n",
      "10020000 2016-11-14 06:08:00.000  0.049416 -0.782285  0.565700   \n",
      "\n",
      "                          labels mapped_category           category_time  \\\n",
      "1332000   7030 sleeping;MET 0.95           lying 2016-11-13 06:00:00.000   \n",
      "1332001   7030 sleeping;MET 0.95           lying 2016-11-13 06:00:00.010   \n",
      "1332002   7030 sleeping;MET 0.95           lying 2016-11-13 06:00:00.020   \n",
      "1332003   7030 sleeping;MET 0.95           lying 2016-11-13 06:00:00.030   \n",
      "1332004   7030 sleeping;MET 0.95           lying 2016-11-13 06:00:00.040   \n",
      "...                          ...             ...                     ...   \n",
      "10019996  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.960   \n",
      "10019997  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.970   \n",
      "10019998  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.980   \n",
      "10019999  7030 sleeping;MET 0.95           lying 2016-11-14 06:07:59.990   \n",
      "10020000  7030 sleeping;MET 0.95           lying 2016-11-14 06:08:00.000   \n",
      "\n",
      "              formatted_time  \n",
      "1332000  2025-01-31 06:00:00  \n",
      "1332001  2025-01-31 06:00:00  \n",
      "1332002  2025-01-31 06:00:00  \n",
      "1332003  2025-01-31 06:00:00  \n",
      "1332004  2025-01-31 06:00:00  \n",
      "...                      ...  \n",
      "10019996 2025-01-31 06:07:59  \n",
      "10019997 2025-01-31 06:07:59  \n",
      "10019998 2025-01-31 06:07:59  \n",
      "10019999 2025-01-31 06:07:59  \n",
      "10020000 2025-01-31 06:08:00  \n",
      "\n",
      "[3608103 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['formatted_time'] = pd.to_datetime(df['formatted_time'])\n",
    "\n",
    "# Filter out times between 01:00:00 and 06:00:00\n",
    "df = df[~((df['formatted_time'].dt.hour >= 1) & (df['formatted_time'].dt.hour < 6))]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "27434edf-02f3-4f02-b19e-9a8379024738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows categorized as 'lying': 5.49%\n",
      "Percentage of rows categorized as 'sitting': 54.11%\n",
      "Percentage of rows categorized as 'walking': 17.07%\n",
      "Percentage of rows categorized as 'house cleaning': 20.26%\n",
      "Percentage of rows categorized as 'standing': 3.07%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentages for each category\n",
    "percentage_lying = 100 * (df['mapped_category'] == 'lying').mean()\n",
    "percentage_sitting = 100 * (df['mapped_category'] == 'sitting').mean()\n",
    "percentage_walking = 100 * (df['mapped_category'] == 'walking').mean()\n",
    "percentage_house_cleaning = 100 * (df['mapped_category'] == 'house_cleaning').mean()\n",
    "percentage_standing = 100 * (df['mapped_category'] == 'standing').mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of rows categorized as 'lying': {percentage_lying:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'sitting': {percentage_sitting:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'walking': {percentage_walking:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'house cleaning': {percentage_house_cleaning:.2f}%\")\n",
    "print(f\"Percentage of rows categorized as 'standing': {percentage_standing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "478e184d-b250-4efd-9d78-3735d707537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after deleting 'annotation' and 'time' columns:\n",
      "                 x         y         z mapped_category      formatted_time\n",
      "1332000  -0.310256  0.073548 -0.958022           lying 2025-01-31 06:00:00\n",
      "1332001  -0.310256  0.057986 -0.958022           lying 2025-01-31 06:00:00\n",
      "1332002  -0.310256  0.057986 -0.958022           lying 2025-01-31 06:00:00\n",
      "1332003  -0.310256  0.073548 -0.958022           lying 2025-01-31 06:00:00\n",
      "1332004  -0.310256  0.057986 -0.958022           lying 2025-01-31 06:00:00\n",
      "...            ...       ...       ...             ...                 ...\n",
      "10019996  0.049416 -0.797846  0.565700           lying 2025-01-31 06:07:59\n",
      "10019997  0.049416 -0.782285  0.565700           lying 2025-01-31 06:07:59\n",
      "10019998  0.049416 -0.782285  0.565700           lying 2025-01-31 06:07:59\n",
      "10019999  0.049416 -0.782285  0.565700           lying 2025-01-31 06:07:59\n",
      "10020000  0.049416 -0.782285  0.565700           lying 2025-01-31 06:08:00\n",
      "\n",
      "[3608103 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['labels', 'time', 'category_time'], axis=1)\n",
    "\n",
    "# Display the DataFrame after columns have been deleted\n",
    "print(\"\\nDataFrame after deleting 'annotation' and 'time' columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78c51d74-6de4-4302-a519-61d9c110688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 x         y         z labels      formatted_time\n",
      "1332000  -0.310256  0.073548 -0.958022  lying 2025-01-31 06:00:00\n",
      "1332001  -0.310256  0.057986 -0.958022  lying 2025-01-31 06:00:00\n",
      "1332002  -0.310256  0.057986 -0.958022  lying 2025-01-31 06:00:00\n",
      "1332003  -0.310256  0.073548 -0.958022  lying 2025-01-31 06:00:00\n",
      "1332004  -0.310256  0.057986 -0.958022  lying 2025-01-31 06:00:00\n",
      "...            ...       ...       ...    ...                 ...\n",
      "10019996  0.049416 -0.797846  0.565700  lying 2025-01-31 06:07:59\n",
      "10019997  0.049416 -0.782285  0.565700  lying 2025-01-31 06:07:59\n",
      "10019998  0.049416 -0.782285  0.565700  lying 2025-01-31 06:07:59\n",
      "10019999  0.049416 -0.782285  0.565700  lying 2025-01-31 06:07:59\n",
      "10020000  0.049416 -0.782285  0.565700  lying 2025-01-31 06:08:00\n",
      "\n",
      "[3608103 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Renaming the 'annotation' column to 'labels'\n",
    "df = df.rename(columns={'mapped_category': 'labels'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae20f0-e110-4428-9e88-d81490e716f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output path\n",
    "input_folder = r'C:\\Users\\Gjert\\Masteroppgave\\Datasets\\capture24'\n",
    "output_path = os.path.join(input_folder, 'capture24_labels.csv')\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
